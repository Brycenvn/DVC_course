{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\MLOps\\Hands_on\\DVC\\DVC\n"
     ]
    }
   ],
   "source": [
    "# Set the repository root as a working directory \n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'data_load' didn't change, skipping\n",
      "Stage 'featurize' didn't change, skipping\n",
      "Stage 'data_split' didn't change, skipping\n",
      "Stage 'train' didn't change, skipping\n",
      "Stage 'evaluate' didn't change, skipping\n",
      "Data and pipelines are up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update dvc.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "dvc_yaml = 'dvc.yaml'\n",
    "\n",
    "with open(dvc_yaml, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "config['stages']['evaluate'].update({\n",
    "  'metrics': [{'reports/metrics.json':{'cache':False}}],\n",
    "  'outs': ['reports/confusion_matrix.png']\n",
    "})\n",
    "\n",
    "with open(dvc_yaml, \"w\") as f:\n",
    "    yaml.safe_dump(config, f)\n",
    "print('Update dvc.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                  f1_score\n",
      "reports\\metrics.json  0.93056\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                  Metric    HEAD    workspace    Change\n",
      "reports\\metrics.json  f1_score  -       0.93056      -\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!git add dvc.lock\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric tracking with DVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update params.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "params_yaml = 'params.yaml'\n",
    "\n",
    "with open(params_yaml, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "config['train'].update({\n",
    "  'cv': 5,\n",
    "  'estimator_name': 'svm',\n",
    "})\n",
    "\n",
    "with open(params_yaml, \"w\") as f:\n",
    "    yaml.safe_dump(config, f)\n",
    "print('Update params.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"\": {\"data\": {\"reports\\\\metrics.json\": {\"data\": {\"f1_score\": 1.0}}}}}\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating lock file 'dvc.lock'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: failed to commit - output 'auc.json' does not exist\n"
     ]
    }
   ],
   "source": [
    "!dvc commit -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: output 'reports\\metrics.json' is specified in:\n",
      "\t- train\n",
      "\t- evaluate\n",
      "Use `dvc remove` with any of the above targets to stop tracking the overlapping output.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                  Metric    HEAD    workspace    Change\n",
      "reports\\metrics.json  f1_score  -       1.0          -\n"
     ]
    }
   ],
   "source": [
    "!dvc metrics diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add metrics tracking\n",
    "\n",
    "Edit `dvc.yaml`, stage `evaluate`:\n",
    "\n",
    "1. add section `metrics`:\n",
    "`dvc.yaml`\n",
    "```yaml\n",
    "...\n",
    "evaluate:\n",
    "    cmd: python src/stages/evaluate.py --config=params.yaml\n",
    "    deps:\n",
    "       ...\n",
    "    params:\n",
    "       ...\n",
    "    metrics:\n",
    "        \n",
    "    outs:\n",
    "    - reports/confusion_matrix.png\n",
    "    - reports/metrics.json\n",
    "    - reports/cm_plot.csv\n",
    "```\n",
    "Here we will:\n",
    "\n",
    "- add metrics tracking\n",
    "- add plots\n",
    "- create experiments with different configurations\n",
    "- compare metrics for different experiments using _DVC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. move `reports/metrics.json` from `outs` to `metrics` section, you should get the following:\n",
    "\n",
    "`dvc.yaml`\n",
    "```yaml\n",
    "...\n",
    "evaluate:\n",
    "    cmd: python src/stages/evaluate.py --config=params.yaml\n",
    "    deps:\n",
    "    - data/processed/test_iris.csv\n",
    "    - models/model.joblib\n",
    "    - src/stages/evaluate.py\n",
    "    params:\n",
    "    - base\n",
    "    - data_split.testset_path\n",
    "    - evaluate\n",
    "    - featurize.target_column\n",
    "    metrics:\n",
    "    - reports/metrics.json\n",
    "    outs:\n",
    "    - reports/confusion_matrix.png\n",
    "    - reports/cm_plot.csv\n",
    "```\n",
    "\n",
    "\n",
    "3. To add metrics file under git control turn off caching them:\n",
    "\n",
    "`dvc.yaml`\n",
    "```yaml\n",
    "...\n",
    "evaluate:\n",
    "    cmd: python src/stages/evaluate.py --config=params.yaml\n",
    "    deps:\n",
    "    - data/processed/test_iris.csv\n",
    "    - models/model.joblib\n",
    "    - src/stages/evaluate.py\n",
    "    params:\n",
    "    - base\n",
    "    - data_split.testset_path\n",
    "    - evaluate\n",
    "    - featurize.target_column\n",
    "    metrics:\n",
    "    - reports/metrics.json\n",
    "    outs:\n",
    "    - reports/confusion_matrix.png\n",
    "    - reports/cm_plot.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add plots\n",
    "\n",
    "Artifact `reports/cm_plot.csv` represents csv format of DVC plot metrics. DVC provides building plots by plot metrics files.\n",
    "\n",
    "To make artifact plot metrics file move `reports/cm_plot.csv` from `outs` to `plots` section (like with metrics):\n",
    "\n",
    "\n",
    "`dvc.yaml`\n",
    "```yaml\n",
    "...\n",
    "evaluate:\n",
    "    cmd: python src/stages/evaluate.py --config=params.yaml\n",
    "    deps:\n",
    "    - data/processed/test_iris.csv\n",
    "    - models/model.joblib\n",
    "    - src/stages/evaluate.py\n",
    "    params:\n",
    "    - base\n",
    "    - data_split.testset_path\n",
    "    - evaluate\n",
    "    - featurize.target_column\n",
    "    metrics:\n",
    "    - reports/metrics.json:\n",
    "        cache: false\n",
    "    plots:\n",
    "    - reports/cm_plot.csv:\n",
    "        cache: false\n",
    "    outs:\n",
    "    - reports/confusion_matrix.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Tune LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run exeperiment\n",
    "\n",
    "\n",
    "Create experiment and change parameter - add options for **C** hyperparamter in section `train:estimators:logreg:param_grid`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproducing experiment 'exp1-tune-logreg'\n",
      "Stage 'data_load' didn't change, skipping\n",
      "Stage 'featurize' didn't change, skipping\n",
      "Stage 'data_split' didn't change, skipping\n",
      "Stage 'train' didn't change, skipping\n",
      "Running stage 'evaluate':\n",
      "> python src/stages/evaluate.py --config=params.yaml\n",
      "2024-10-11 17:23:34,365 — EVALUATE — INFO — Load model\n",
      "2024-10-11 17:23:34,415 — EVALUATE — INFO — Load test dataset\n",
      "2024-10-11 17:23:34,418 — EVALUATE — INFO — Evaluate (build report)\n",
      "2024-10-11 17:23:34,421 — EVALUATE — INFO — Save metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\MLOps\\Hands_on\\DVC\\DVC\\src\\stages\\evaluate.py\", line 79, in <module>\n",
      "    evaluate_model(config_path=args.config)\n",
      "  File \"d:\\MLOps\\Hands_on\\DVC\\DVC\\src\\stages\\evaluate.py\", line 53, in evaluate_model\n",
      "    reports_folder = Path(config['evaluate']['reports_dir'])\n",
      "                          ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyError: 'reports_dir'\n",
      "ERROR: failed to reproduce 'evaluate': failed to run: python src/stages/evaluate.py --config=params.yaml, exited with 1\n"
     ]
    }
   ],
   "source": [
    "!dvc exp run -n exp1-tune-logreg \\\n",
    "    --set-param train.estimators.logreg.param_grid.C=[0.1,1.0,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "as result you should have LogisticRegression config:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "train:\n",
    "  cv: 3\n",
    "  estimator_name: logreg\n",
    "\n",
    "  estimators:\n",
    "\n",
    "    logreg: # sklearn.linear_model.LogisticRegression\n",
    "      param_grid: # params of GridSearchCV constructor\n",
    "        C:\n",
    "        - 0.1\n",
    "        - 1.0\n",
    "        - 10\n",
    "        max_iter: [100]\n",
    "        solver: [lbfgs]\n",
    "        multi_class: [multinomial]\n",
    "...\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit experiment results\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"Experiment 1 with LogisticRegression hyperparameters\"\n",
    "git tag -a \"exp1_tune_logreg\" -m \"Experiment 1 with LogisticRegression hyperparameters\"\n",
    "dvc push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics \n",
    "\n",
    "```bash\n",
    "dvc metrics show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - Use SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run experiment\n",
    "\n",
    "in section `train` change:\n",
    "    - `estimator_name`\n",
    "    - change `estimators:svm:param_grid:C`\n",
    "\n",
    "\n",
    "```bash\n",
    "dvc exp run -n exp2-svm \\\n",
    "    --set-param train.estimator_name=svm \\\n",
    "    --set-param train.estimators.svm.param_grid.C=[0.1,1.0,10]\n",
    "```\n",
    "\n",
    "\n",
    "as result you should have SVC config:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "train:\n",
    "  cv: 3\n",
    "  estimator_name: svm\n",
    "  estimators:\n",
    "        \n",
    "    svm: # sklearn.svm.SVC\n",
    "      param_grid:\n",
    "        C:\n",
    "        - 0.1\n",
    "        - 1.0\n",
    "        - 10\n",
    "        kernel: [rbf, linear]\n",
    "        gamma: [scale]\n",
    "        degree: [3, 5]\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit experiment results\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"Experiment 2 with SVM estimator\"\n",
    "git tag -a \"exp2_svm\" -m \"Experiment 2 with SVM estimator\"\n",
    "dvc push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics \n",
    "\n",
    "```bash\n",
    "dvc metrics show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare experiments\n",
    "\n",
    "1. List experiments:\n",
    "\n",
    "```bash\n",
    "dvc exp list --all\n",
    "```\n",
    "```\n",
    "# output\n",
    "940fee6:                                                              \n",
    "        exp2-svm\n",
    "step-6:\n",
    "        exp1-tune-logreg\n",
    "\n",
    "```\n",
    "\n",
    "2. Compare current experiments`:\n",
    "\n",
    "```bash\n",
    "dvc exp diff --old  exp1-tune-logreg exp2-svm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push changes to remote repository\n",
    "\n",
    "```bash\n",
    "git push origin step-6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVC Studio\n",
    "\n",
    "\n",
    "## View creation\n",
    "\n",
    "1. Open [DVC Studio](https://studio.iterative.ai/) and sing up/sing in.\n",
    "\n",
    "2. Create **View**: click **Add a view**\n",
    "\n",
    "3. Select repository\n",
    "\n",
    "## Work with View\n",
    "\n",
    "1. Enter `View`\n",
    "\n",
    "2. Navigate the branch `step-6`\n",
    "\n",
    "3. Select one of commits and click `Show plots` - you'll see plots built by `DVC Studio` for selected commit\n",
    "\n",
    "4. Select any **two commits** to compare it and click `Compare` - `DVS Studio` will build comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
